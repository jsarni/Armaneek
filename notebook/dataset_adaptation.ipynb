{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MPST_DATASET = \"../dataset/mpts/mpst_full_data.csv\"\n",
    "FUNCTIONAL_WORDS_FILE = \"../dataset/function_words.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file):\n",
    "    dataframe = pd.read_csv(file)\n",
    "    all_categories = extract_categories(dataframe)\n",
    "    movies_and_categories = {}\n",
    "    for category in all_categories:\n",
    "        category_movies = []\n",
    "        category_data = dataframe[dataframe[\"tags\"].str.contains(category)][[\"title\", \"plot_synopsis\"]].values.tolist()\n",
    "        for film in category_data:\n",
    "            film_dict = {\"title\": film[0], \"synopsis\": film[1]}\n",
    "            category_movies.append(film_dict)\n",
    "        movies_and_categories[category] = category_movies\n",
    "    return movies_and_categories\n",
    "\n",
    "def extract_categories(df):\n",
    "    raw_categories = [[cat for cat in cats.split(\", \")] for cats in df[\"tags\"].tolist()]\n",
    "    categories = []\n",
    "    for sublist in raw_categories:\n",
    "        for category in sublist:\n",
    "            categories.append(category)\n",
    "    categories = set(categories)\n",
    "    return categories\n",
    "\n",
    "def get_n_categories(films_with_categories, n):\n",
    "    categories = list(films_with_categories.keys())\n",
    "    nb_fils_cat = {}\n",
    "    for cat in categories:\n",
    "        nb_films = len(films_with_categories[cat])\n",
    "        nb_fils_cat[cat] = nb_films\n",
    "    sorted_cats = dict(sorted(nb_fils_cat.items(), key=lambda item: item[1], reverse=True))\n",
    "    n_cats = list(sorted_cats.keys())[:n]\n",
    "    return n_cats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_films = load_data(MPST_DATASET)\n",
    "## We'll only work on the 5 most represented categories\n",
    "n_categories = get_n_categories(all_films, 5)\n",
    "n_categories_films = { category: all_films[category] for category in n_categories }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "murder - 5782 films\n",
      "violence - 4426 films\n",
      "flashback - 2937 films\n",
      "romantic - 2906 films\n",
      "cult - 2647 films\n"
     ]
    }
   ],
   "source": [
    "for category in n_categories_films.keys():\n",
    "    print(f\"{category} - {len(n_categories_films[category])} films\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## /!\\ Deprecated /!\\ - Generate dataset to markovify intros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in n_categories_films.keys():\n",
    "    category_file = f\"../dataset/markovify_train/{category}.txt\"\n",
    "    file = open(category_file, 'a')\n",
    "    nb_films = len(n_categories_films[category])\n",
    "    for i in range(nb_films):\n",
    "        synopsis_intro = \".\".join(n_categories_films[category][i][\"synopsis\"].replace(\"\\n\", \" \").split(\".\")[:3])\n",
    "        file.write(n_categories_films[category][i][\"synopsis\"].replace(\"\\n\", \" \"))\n",
    "        file.write(\"\\n\")\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptation of the dataset to create corpus for each of the 5 major movie categories of the MPTS dataset\n",
    "### This Notebook is also used to clean the dataset from all actors names specifically, and all parenthesis content as they were causing learning problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in n_categories_films.keys():\n",
    "    nb_films = len(n_categories_films[category])\n",
    "    for i in range(nb_films):\n",
    "        film_file = f\"../dataset/transformers_train/{category}/{i}.txt\"\n",
    "        file = open(film_file, 'w')\n",
    "        clean_synopsis = re.sub(r'\\([^)]*\\)', '', n_categories_films[category][i][\"synopsis\"])\n",
    "        file.write(clean_synopsis)\n",
    "    file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
