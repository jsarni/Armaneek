{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MPST_DATASET = \"../dataset/mpts/mpst_full_data.csv\"\n",
    "FUNCTIONAL_WORDS_FILE = \"../dataset/function_words.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file):\n",
    "    dataframe = pd.read_csv(file)\n",
    "    all_categories = extract_categories(dataframe)\n",
    "    movies_and_categories = {}\n",
    "    for category in all_categories:\n",
    "        category_movies = []\n",
    "        category_data = dataframe[dataframe[\"tags\"].str.contains(category)][[\"title\", \"plot_synopsis\"]].values.tolist()\n",
    "        for film in category_data:\n",
    "            film_dict = {\"title\": film[0], \"synopsis\": film[1]}\n",
    "            category_movies.append(film_dict)\n",
    "        movies_and_categories[category] = category_movies\n",
    "    return movies_and_categories\n",
    "\n",
    "def extract_categories(df):\n",
    "    raw_categories = [[cat for cat in cats.split(\", \")] for cats in df[\"tags\"].tolist()]\n",
    "    categories = []\n",
    "    for sublist in raw_categories:\n",
    "        for category in sublist:\n",
    "            categories.append(category)\n",
    "    categories = set(categories)\n",
    "    return categories\n",
    "\n",
    "# def load_functional_words():\n",
    "#     with open(FUNCTIONAL_WORDS_FILE) as f:\n",
    "#         function_words = set(f.read().splitlines())\n",
    "#     return function_words\n",
    "\n",
    "def get_n_categories(films_with_categories, n):\n",
    "    categories = list(films_with_categories.keys())\n",
    "    nb_fils_cat = {}\n",
    "    for cat in categories:\n",
    "        nb_films = len(films_with_categories[cat])\n",
    "        nb_fils_cat[cat] = nb_films\n",
    "    sorted_cats = dict(sorted(nb_fils_cat.items(), key=lambda item: item[1], reverse=True))\n",
    "    n_cats = list(sorted_cats.keys())[:n]\n",
    "    return n_cats\n",
    "\n",
    "\n",
    "# def count_words(films_with_categories, categories):\n",
    "#     number_of_seen_synopsis = 0\n",
    "#     function_words = load_functional_words()\n",
    "#     nlp_en = spacy.load('en_core_web_lg')\n",
    "    \n",
    "#     titles = {}\n",
    "#     words_count = {}\n",
    "    \n",
    "#     for category in categories:\n",
    "#         category_titles = []\n",
    "#         for synopsis in films_with_categories[category]:\n",
    "#             doc_en = nlp_en(synopsis[\"synopsis\"])\n",
    "#             number_of_seen_synopsis += 1\n",
    "#             print(number_of_seen_synopsis)\n",
    "#             category_titles.append(synopsis[\"title\"])\n",
    "            \n",
    "#             contents = [\n",
    "#                 word.lower() for word in\n",
    "#                 nltk.word_tokenize(synopsis[\"synopsis\"])\n",
    "#                 if word.isalpha()\n",
    "#             ]\n",
    "#             if category not in words_count.keys():\n",
    "#                 words_count[category] = {}\n",
    "            \n",
    "#             for word in contents:\n",
    "#                 for ent in doc_en.ents:\n",
    "#                     if (word in ent.text) and (ent.label_ == 'PERSON'):\n",
    "#                         continue\n",
    "#                 if word in function_words:\n",
    "#                     continue\n",
    "#                 elif word not in words_count[category]:\n",
    "#                     words_count[category][word] = 1\n",
    "#                 else:\n",
    "#                     words_count[category][word] += 1\n",
    "#         titles[category] = category_titles\n",
    "#     return words_count, titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_films = load_data(MPST_DATASET)\n",
    "n_categories = get_n_categories(all_films, 5)\n",
    "n_categories_films = { category: all_films[category] for category in n_categories }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "murder - 5782 films\n",
      "violence - 4426 films\n",
      "flashback - 2937 films\n",
      "romantic - 2906 films\n",
      "cult - 2647 films\n"
     ]
    }
   ],
   "source": [
    "for category in n_categories_films.keys():\n",
    "    print(f\"{category} - {len(n_categories_films[category])} films\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\\n\" in n_categories_films[\"murder\"][2][\"synopsis\"].replace(\"\\n\", \" \")\n",
    "# n_categories_films[\"murder\"][2][\"synopsis\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate dataset to markovify intros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in n_categories_films.keys():\n",
    "    category_file = f\"../dataset/markovify_train/{category}.txt\"\n",
    "    file = open(category_file, 'a')\n",
    "    nb_films = len(n_categories_films[category])\n",
    "    for i in range(nb_films):\n",
    "        synopsis_intro = \".\".join(n_categories_films[category][i][\"synopsis\"].replace(\"\\n\", \" \").split(\".\")[:3])\n",
    "        file.write(n_categories_films[category][i][\"synopsis\"].replace(\"\\n\", \" \"))\n",
    "        file.write(\"\\n\")\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in n_categories_films.keys():\n",
    "    nb_films = len(n_categories_films[category])\n",
    "    for i in range(nb_films):\n",
    "        film_file = f\"../dataset/transformers_train/{category}/{i}.txt\"\n",
    "        file = open(film_file, 'w')\n",
    "        clean_synopsis = re.sub(r'\\([^)]*\\)', '', n_categories_films[category][i][\"synopsis\"])\n",
    "        file.write(clean_synopsis)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The movie begins with a video being shot of men with their hands tied behind their backs',\n",
       " ' An enforcer, who we learn later is Lado (Benicio Del Toro) wears a skull Lucha libre mask and runs a chainsaw',\n",
       " \"Next, there is a shot of an attractive young blonde woman named 'O' (short for Ophelia, played by Blake Lively) as she narrates in a voice-over\"]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_categories_films[\"murder\"][3][\"synopsis\"].split(\".\")[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
